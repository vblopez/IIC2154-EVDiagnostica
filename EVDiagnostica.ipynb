{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "02c9364c",
   "metadata": {},
   "source": [
    "## Evaluación diagnostica gitflow"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca67eb0c",
   "metadata": {},
   "source": [
    "Programar en Python cuatro funciones:\n",
    "\n",
    "1. Los top 10 tweets más retweeted.\n",
    "2. Los top 10 usuarios en función a la cantidad de tweets que emitieron.\n",
    "3. Los top 10 días donde hay más tweets.\n",
    "4. Top 10 hashtags más usados.\n",
    "Dataset: https://www.kaggle.com/datasets/prathamsharma123/farmers-protest-tweets-dataset-raw-json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "618450dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import\n",
    "import json\n",
    "import re\n",
    "from heapq import nlargest \n",
    "import pandas as pd\n",
    "from pandas.io.json import json_normalize\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1e4c3c2",
   "metadata": {},
   "source": [
    "### Función top retweeted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "edaaedb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def top_retweets(df, ntop = 10 ):\n",
    "    \"\"\" función que calcula el top N° ntop\n",
    "    de tweets más retweteados de data\n",
    "    \"\"\"\n",
    "    top = df.nlargest(n=ntop, columns=['retweetCount'])\n",
    "    return top"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0297bb22",
   "metadata": {},
   "source": [
    "### Funcion top users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "757072c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def top_users(df, ntop = 10 ):\n",
    "    \"\"\" función que calcula el top N° ntop\n",
    "    de usuarios que han hecho más tweets\n",
    "    \"\"\"\n",
    "    df1 = df.groupby(['username']).count()\n",
    "    df1 = df1.reset_index()\n",
    "    df1['cant_tweets'] = df1['tweetId']\n",
    "    top = df1.nlargest(n=ntop, columns=['cant_tweets'])\n",
    "    cols = ['username','cant_tweets']\n",
    "    top_clean = top[cols]\n",
    "    top_clean = top_clean.reset_index()\n",
    "    return top_clean"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "920e7abe",
   "metadata": {},
   "source": [
    "### Función top days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5280dbb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def top_days(df, ntop = 10 ):\n",
    "    \"\"\" función que calcula el top N° ntop\n",
    "    de dias que se han hecho más tweets\n",
    "    \"\"\"\n",
    "    df1 = df.groupby(['day']).count()\n",
    "    df1 = df1.reset_index()\n",
    "    df1['cant_tweets'] = df1['tweetId']\n",
    "    top = df1.nlargest(n=ntop, columns=['cant_tweets'])\n",
    "    cols = ['day','cant_tweets']\n",
    "    top_clean = top[cols]\n",
    "    top_clean = top_clean.reset_index()\n",
    "    return top_clean"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93d9fcfe",
   "metadata": {},
   "source": [
    "### Función top hashtags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b82948e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def top_hashtags(df, ntop = 10 ):\n",
    "    top = 3\n",
    "    freq = {}\n",
    "    regex = \"#(\\w+)\"\n",
    "    for tweet in df[\"renderedContent\"]:\n",
    "        hashtag_list = re.findall(regex, tweet)\n",
    "        for hashtag in hashtag_list:\n",
    "            if hashtag in freq.keys():\n",
    "                freq[hashtag] += 1\n",
    "            else: \n",
    "                freq[hashtag] = 1\n",
    "    top = nlargest(ntop, freq, key = freq.get) \n",
    "    return top"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec92e4d4",
   "metadata": {},
   "source": [
    "### Preprocesamiento dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "597cc664",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_data(path_archivo):\n",
    "    raw_tweets = pd.read_json(path_archivo, lines=True)\n",
    "    raw_tweets = raw_tweets[raw_tweets['lang']=='en']\n",
    "    # Normalize 'user' field\n",
    "    users = json_normalize(raw_tweets['user'])\n",
    "    users.drop(['description', 'linkTcourl'], axis=1, inplace=True)\n",
    "    users.rename(columns={'id':'userId', 'url':'profileUrl'}, inplace=True)\n",
    "    # Create DataFrame and remove duplicates\n",
    "    users = pd.DataFrame(users)\n",
    "    users.drop_duplicates(subset=['userId'], inplace=True)\n",
    "    # Add column for 'userId'\n",
    "    user_id = []\n",
    "    user_name = []\n",
    "    for user in raw_tweets['user']:\n",
    "        uid = user['id']\n",
    "        name = user['username']\n",
    "        user_id.append(uid)\n",
    "        user_name.append(name)\n",
    "    raw_tweets['userId'] = user_id\n",
    "    raw_tweets['username'] = user_name\n",
    "    # Remove less important columns\n",
    "    cols = ['url', 'date', 'renderedContent', 'id', 'username', 'userId', 'replyCount', 'retweetCount', 'likeCount', 'quoteCount', 'source', 'media', 'retweetedTweet', 'quotedTweet', 'mentionedUsers']\n",
    "    tweets = raw_tweets[cols]\n",
    "    tweets.rename(columns={'id':'tweetId', 'url':'tweetUrl'}, inplace=True)\n",
    "    # Convert to DataFrame, remove duplicates and keep only English tweets\n",
    "    tweets = pd.DataFrame(tweets)\n",
    "    tweets.drop_duplicates(subset=['tweetId'], inplace=True)\n",
    "    return tweets"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
